{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PTQ"
      ],
      "metadata": {
        "id": "HVjv4rHrpVmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.quantization as quantization\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class PTQModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = quantization.QuantStub()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
        "        self.dequant = quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "def train_fp32_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def apply_ptq_with_calibration(model, calibration_loader):\n",
        "    model.eval()\n",
        "    model.qconfig = quantization.get_default_qconfig(\"x86\")\n",
        "    model_fused = quantization.fuse_modules(model, [[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\", \"relu2\"]])\n",
        "    model_prepared = quantization.prepare(model_fused)\n",
        "    with torch.no_grad():\n",
        "        for images, _ in calibration_loader:\n",
        "            model_prepared(images)\n",
        "    model_int8 = quantization.convert(model_prepared)\n",
        "    return model_int8\n",
        "\n",
        "\n",
        "model_fp32 = PTQModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_fp32.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training FP32 model...\")\n",
        "train_fp32_model(model_fp32, train_loader, criterion, optimizer, epochs=5)\n",
        "\n",
        "print(\"Evaluating FP32 model...\")\n",
        "evaluate_model(model_fp32, test_loader)\n",
        "\n",
        "print(\"Applying PTQ with calibration...\")\n",
        "calibration_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "model_int8 = apply_ptq_with_calibration(model_fp32, calibration_loader)\n",
        "\n",
        "print(\"Evaluating INT8 model...\")\n",
        "evaluate_model(model_int8, test_loader)"
      ],
      "metadata": {
        "id": "9EqAvaEle2N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdb155a-64f9-423f-ab49-586c9a0bb8d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training FP32 model...\n",
            "Epoch [1/5], Loss: 0.1524\n",
            "Epoch [2/5], Loss: 0.0544\n",
            "Epoch [3/5], Loss: 0.0380\n",
            "Epoch [4/5], Loss: 0.0279\n",
            "Epoch [5/5], Loss: 0.0196\n",
            "Evaluating FP32 model...\n",
            "Accuracy: 98.39%\n",
            "Applying PTQ with calibration...\n",
            "Evaluating INT8 model...\n",
            "Accuracy: 98.35%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.35"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QAT"
      ],
      "metadata": {
        "id": "Xgs5cf2epSeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.ao.quantization as quantization\n",
        "\n",
        "class QATModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.quant = quantization.QuantStub()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
        "        self.dequant = quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "def get_data_loaders(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def training_loop(model, train_loader, criterion, optimizer, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "train_loader, test_loader = get_data_loaders()\n",
        "\n",
        "model_fp32 = QATModel()\n",
        "model_fp32.qconfig = quantization.get_default_qat_qconfig('x86')\n",
        "\n",
        "model_fp32.eval()\n",
        "model_fp32_fused = quantization.fuse_modules(model_fp32,[[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\", \"relu2\"]])\n",
        "\n",
        "model_fp32_prepared = quantization.prepare_qat(model_fp32_fused.train())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_fp32_prepared.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training QAT model...\")\n",
        "training_loop(model_fp32_prepared, train_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "print(\"Converting to INT8 model...\")\n",
        "model_fp32_prepared.eval()\n",
        "model_int8 = quantization.convert(model_fp32_prepared)\n",
        "\n",
        "print(\"Evaluating INT8 model...\")\n",
        "evaluate_model(model_int8, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgBYocdBeM-k",
        "outputId": "e9d4e746-4ca8-40e7-b5fb-3ce7f15394e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training QAT model...\n",
            "Epoch [1/5], Loss: 0.2276\n",
            "Epoch [2/5], Loss: 0.0575\n",
            "Epoch [3/5], Loss: 0.0399\n",
            "Epoch [4/5], Loss: 0.0300\n",
            "Epoch [5/5], Loss: 0.0211\n",
            "Converting to INT8 model...\n",
            "Evaluating INT8 model...\n",
            "Accuracy: 98.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "양자화 성공적인지 확인"
      ],
      "metadata": {
        "id": "lZ34UJh6mIDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_int8.conv1.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owEmYdDQkOK-",
        "outputId": "9d997ddd-f6dd-40d9-81df-e171e49fd2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Conv2d.weight of QuantizedConvReLU2d(1, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.016592519357800484, zero_point=0, padding=(1, 1))>\n"
          ]
        }
      ]
    }
  ]
}
